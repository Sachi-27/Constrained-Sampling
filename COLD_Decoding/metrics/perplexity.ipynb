{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/raid/speech/sabyasachi/Translation/COLD_decoding/data/commongen/commongen.dev.jsonl\", \"r\") as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "sentences = []\n",
    "for i in range(len(data)):\n",
    "\n",
    "    sentences.append(data[i][\"scene\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "end = 6\n",
    "sentences = sentences[start:end]\n",
    "# sentences.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/raid/speech/sabyasachi/Translation/COLD_decoding/data/commongen/topk_changes/0f_zx_seed12_0_5_lexical_generation_cw0.500_c2w0.100_lrnllp0.600_len10_topk2_niter2000_frozlen0_winiter1000_noiseiter1_gsstd0.0100_lr0.100_lrratio1.00_lriter1000_50,500,1000,1500_1,0.5,0.1,0.05_output.json\") as f:\n",
    "    pred_data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sentences = []\n",
    "\n",
    "for i in range(len(pred_data)):\n",
    "    pred_sentences.append(pred_data[i][\"generation_complete\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(\n",
    "    'gpt2-xl', output_hidden_states=True,\n",
    "    resid_pdrop=0, embd_pdrop=0, attn_pdrop=0, summary_first_dropout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-xl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPL_avg = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPL_generated = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pred_sentences)):\n",
    "    PPL = []\n",
    "    for j in range(5):\n",
    "        inputs = tokenizer(pred_sentences[i][j], return_tensors = \"pt\")\n",
    "        loss = model(input_ids = inputs[\"input_ids\"], labels = inputs[\"input_ids\"]).loss\n",
    "        ppl = torch.exp(loss).item()\n",
    "        # PPL_generated[pred_sentences[i][j]] = np.round(ppl, 2)\n",
    "        PPL.append(ppl)\n",
    "    PPL_avg.append(np.mean(PPL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_gen = json.dumps(PPL_generated, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"perplexity_gen.json\", \"w\") as outfile:\n",
    "#     outfile.write(json_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPL_avg_orig = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPL_ref = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    # PPL = []\n",
    "    for j in range(len(sentences[i])):\n",
    "        inputs = tokenizer(sentences[i][j], return_tensors = \"pt\")\n",
    "        loss = model(input_ids = inputs[\"input_ids\"], labels = inputs[\"input_ids\"]).loss\n",
    "        ppl = torch.exp(loss).item()\n",
    "        # PPL_ref[sentences[i][j]] = np.round(ppl, 2)\n",
    "        PPL.append(ppl)\n",
    "    PPL_avg_orig.append(np.mean(PPL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_ref = json.dumps(PPL_ref, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"perplexity_ref.json\", \"w\") as outfile:\n",
    "#     outfile.write(json_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated 28.580418157577515\n",
      "reference 104.51772686677252\n"
     ]
    }
   ],
   "source": [
    "print(\"generated\", np.mean(PPL_avg))\n",
    "print(\"reference\", np.mean(PPL_avg_orig))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "menv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
